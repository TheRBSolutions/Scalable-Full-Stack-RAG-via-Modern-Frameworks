---
id: intro
title: What is Physical AI?
---

# Introduction to Physical AI: The Embodiment of Intelligence

Physical AI represents the transition from "Internet AI"—which lives in servers and processes pixels and text—to "Embodied AI," which interacts with the physical world. While a chatbot can explain how to tie a shoe, Physical AI must actually perform the task, navigating the complex variables of friction, gravity, and material deformation.

## The Three Pillars of Physical AI
To understand Physical AI, we must look at the intersection of three distinct fields:
1. **Computer Vision & Perception:** The ability to move beyond 2D image recognition into 3D spatial awareness.
2. **Foundation Models (LLMs/VLM):** Using massive datasets to give robots "common sense" reasoning.
3. **Actuation & Control:** The hardware and math required to translate a digital thought into a physical movement.

## From Rigid Automation to General Purpose Robotics
For decades, industrial robots were "blind." They followed a fixed script in a cage. Physical AI changes this by introducing the **Perception-Action Loop**. The robot observes an environment, processes the change via a neural network, and adjusts its motor torque in milliseconds. This is the difference between a robot that can only build one specific car part and a robot that can walk into any kitchen and wash a dish it has never seen before.

## The Sim-to-Real Challenge
A major part of Physical AI development happens in simulation. Using platforms like NVIDIA Isaac Gym, researchers train robots in "digital twins." The "Sim-to-Real Gap" is the mathematical difference between a simulated floor and a real, slippery, uneven surface. Closing this gap is the primary focus of modern robotics research.

### Key Takeaways
- Physical AI is the "body" for the AI "brain."
- It relies on real-time feedback loops rather than static commands.
- The goal is General Purpose Robotics (GPR).